"""
Streamlit å‰ç«¯ - æ®µè½çº§åˆ« AIGC æ£€æµ‹å·¥å…·
æ”¯æŒé€æ®µè½æ£€æµ‹å’Œå¯è§†åŒ–æ˜¾ç¤º
"""

import streamlit as st
import pandas as pd
from advanced_detector import ChineseAIGCDetector
import plotly.graph_objects as go
from typing import List, Dict
import re
import PyPDF2
from docx import Document
import io

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="AIGC ä¸­æ–‡æ£€æµ‹å™¨",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰ CSS
st.markdown("""
    <style>
    /* ç´§å‡‘å¼æ®µè½æ ·å¼ - ç±»ä¼¼åŸæ–‡å¸ƒå±€ */
    .compact-text-container {
        font-size: 16px;
        line-height: 1.8;
        margin: 20px 0;
        padding: 0;
    }
    .text-segment {
        display: inline;
        padding: 2px 0;
        line-height: 1.8;
        transition: all 0.2s ease;
    }
    .text-segment:hover {
        opacity: 0.85;
        cursor: pointer;
    }
    /* AI ç‡é«˜ - çº¢è‰²èƒŒæ™¯ */
    .highlight-high {
        background-color: rgba(255, 100, 100, 0.25);
        border-bottom: 2px solid #ff6464;
    }
    /* AI ç‡ä¸­ - é»„è‰²èƒŒæ™¯ */
    .highlight-medium {
        background-color: rgba(255, 193, 7, 0.25);
        border-bottom: 2px solid #ffc107;
    }
    /* AI ç‡ä½ - ç»¿è‰²èƒŒæ™¯ */
    .highlight-low {
        background-color: rgba(76, 175, 80, 0.2);
        border-bottom: 2px solid #4caf50;
    }
    /* å†…è”æ ‡è®° */
    .inline-badge {
        display: inline-block;
        font-size: 11px;
        padding: 2px 6px;
        margin: 0 3px;
        border-radius: 3px;
        font-weight: bold;
        vertical-align: super;
        line-height: 1;
    }
    .inline-badge-high {
        background-color: #ff6464;
        color: white;
    }
    .inline-badge-medium {
        background-color: #ffc107;
        color: #333;
    }
    .inline-badge-low {
        background-color: #4caf50;
        color: white;
    }
    /* å›¾ä¾‹ */
    .legend-container {
        display: flex;
        gap: 20px;
        padding: 15px;
        background-color: #f8f9fa;
        border-radius: 8px;
        margin: 15px 0;
        font-size: 14px;
    }
    .legend-item {
        display: flex;
        align-items: center;
        gap: 8px;
    }
    .legend-color {
        width: 40px;
        height: 20px;
        border-radius: 3px;
        border: 1px solid #ddd;
    }
    </style>
""", unsafe_allow_html=True)


@st.cache_resource
def load_detector(language="chinese"):
    """åŠ è½½æ£€æµ‹å™¨ï¼ˆç¼“å­˜ï¼‰"""
    with st.spinner("æ­£åœ¨åŠ è½½æ¨¡å‹..."):
        detector = ChineseAIGCDetector(device="cpu", language=language)
    return detector


def extract_text_from_pdf(file) -> str:
    """
    ä» PDF æ–‡ä»¶æå–æ–‡æœ¬
    
    Args:
        file: ä¸Šä¼ çš„ PDF æ–‡ä»¶å¯¹è±¡
        
    Returns:
        æå–çš„æ–‡æœ¬å†…å®¹
    """
    try:
        pdf_reader = PyPDF2.PdfReader(file)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text() + "\n"
        return text.strip()
    except Exception as e:
        st.error(f"PDF è§£æå¤±è´¥: {str(e)}")
        return ""


def extract_text_from_docx(file) -> str:
    """
    ä» Word æ–‡æ¡£æå–æ–‡æœ¬
    
    Args:
        file: ä¸Šä¼ çš„ Word æ–‡ä»¶å¯¹è±¡
        
    Returns:
        æå–çš„æ–‡æœ¬å†…å®¹
    """
    try:
        doc = Document(file)
        text = "\n".join([paragraph.text for paragraph in doc.paragraphs])
        return text.strip()
    except Exception as e:
        st.error(f"Word æ–‡æ¡£è§£æå¤±è´¥: {str(e)}")
        return ""


def extract_chinese_from_tex(file) -> str:
    """
    ä» LaTeX (.tex) æ–‡ä»¶ä¸­æå–æ­£æ–‡å†…å®¹
    åªä¿ç•™ document ç¯å¢ƒå†…çš„ä¸­æ–‡/è‹±æ–‡/æ•°å­—/æ ‡ç‚¹ä¸æ®µè½
    """
    try:
        content = file.read().decode("utf-8", errors="ignore")

        # 0) ä»…å– \begin{document} ... \end{document} å†…çš„æ­£æ–‡
        doc_match = re.search(r"\\begin\{document\}(.*)\\end\{document\}", content, flags=re.S)
        if doc_match:
            content = doc_match.group(1)

        # 1) å»æ³¨é‡Š
        content = re.sub(r"(?m)^%.*$", " ", content)

        # 2) å»\citeå¼•ç”¨
        content = re.sub(r"\\cite\{[^}]*\}", " ", content)

        # 3) å»æ•°å­¦å…¬å¼ (è¡Œé—´/è¡Œå†…)
        math_patterns = [r"\$\$.*?\$\$", r"\\\[.*?\\\]", r"\\\(.*?\\\)", r"\$.*?\$"]
        for pat in math_patterns:
            content = re.sub(pat, " ", content, flags=re.S)

        # 4) å»ç¯å¢ƒå—
        content = re.sub(r"\\begin\{[^}]*\}.*?\\end\{[^}]*\}", " ", content, flags=re.S)

        # 5) å»å‘½ä»¤åä½†ä¿ç•™æ‹¬å·å†…å®¹
        content = re.sub(r"\\[a-zA-Z@]+(\s*\[[^\]]*\])?", " ", content)

        # 6) å»æ‰å¤§æ‹¬å·æœ¬èº«ï¼Œä¿ç•™å†…å®¹
        content = content.replace("{", "").replace("}", "")

        # 7) ä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ã€å¸¸è§æ ‡ç‚¹ä¸æ¢è¡Œ/ç©ºç™½
        allowed = r"[^\u4e00-\u9fffA-Za-z0-9ã€‚ï¼Œï¼ï¼Ÿã€ï¼›ï¼šï¼šï¼ˆï¼‰ã€Šã€‹ã€ã€‘""''â€¦â€”\-\n\r\t ,.;:!\?\(\)\[\]\{\}/'\"`]"
        content = re.sub(allowed, " ", content)

        # 8) è§„èŒƒç©ºç™½ï¼Œä¿ç•™æ®µè½
        content = re.sub(r"[ \t]+", " ", content)
        content = re.sub(r"\n{3,}", "\n\n", content)

        return content.strip()
    except Exception as e:
        st.error(f"TeX è§£æå¤±è´¥: {str(e)}")
        return ""


def extract_text_from_md(file) -> str:
    """
    ä» Markdown (.md) æ–‡ä»¶ä¸­æå–æ–‡æœ¬å†…å®¹
    å»é™¤ Markdown æ ‡è®°ï¼Œä¿ç•™çº¯æ–‡æœ¬
    """
    try:
        content = file.read().decode("utf-8", errors="ignore")
        
        # å»é™¤ä»£ç å—
        content = re.sub(r"```.*?```", " ", content, flags=re.S)
        content = re.sub(r"`[^`]+`", " ", content)
        
        # å»é™¤å›¾ç‰‡é“¾æ¥
        content = re.sub(r"!\[([^\]]*)\]\([^\)]+\)", r"\1", content)
        
        # å»é™¤æ™®é€šé“¾æ¥ï¼Œä¿ç•™æ–‡æœ¬
        content = re.sub(r"\[([^\]]*)\]\([^\)]+\)", r"\1", content)
        
        # å»é™¤æ ‡é¢˜æ ‡è®°
        content = re.sub(r"^#+\s+", "", content, flags=re.M)
        
        # å»é™¤åˆ—è¡¨æ ‡è®°
        content = re.sub(r"^[\*\-\+]\s+", "", content, flags=re.M)
        content = re.sub(r"^\d+\.\s+", "", content, flags=re.M)
        
        # å»é™¤å¼•ç”¨æ ‡è®°
        content = re.sub(r"^>\s+", "", content, flags=re.M)
        
        # å»é™¤æ°´å¹³çº¿
        content = re.sub(r"^[\*\-_]{3,}$", "", content, flags=re.M)
        
        # å»é™¤ç²—ä½“å’Œæ–œä½“æ ‡è®°
        content = re.sub(r"\*\*([^\*]+)\*\*", r"\1", content)
        content = re.sub(r"__([^_]+)__", r"\1", content)
        content = re.sub(r"\*([^\*]+)\*", r"\1", content)
        content = re.sub(r"_([^_]+)_", r"\1", content)
        
        # è§„èŒƒç©ºç™½
        content = re.sub(r"[ \t]+", " ", content)
        content = re.sub(r"\n{3,}", "\n\n", content)
        
        return content.strip()
    except Exception as e:
        st.error(f"Markdown è§£æå¤±è´¥: {str(e)}")
        return ""


def split_into_paragraphs(text: str) -> List[str]:
    """
    å°†æ–‡æœ¬åˆ†å‰²ä¸ºæ®µè½
    
    Args:
        text: è¾“å…¥æ–‡æœ¬
        
    Returns:
        æ®µè½åˆ—è¡¨
    """
    # æŒ‰ç©ºè¡Œæˆ–å¤šä¸ªå¥å·åˆ†å‰²
    paragraphs = re.split(r'[\n\n]+|(?<=[ã€‚ï¼ï¼Ÿ])\s+', text.strip())
    # è¿‡æ»¤ç©ºæ®µè½
    paragraphs = [p.strip() for p in paragraphs if p.strip()]
    return paragraphs


def get_ai_rate_color(ai_prob: float) -> str:
    """æ ¹æ® AI æ¦‚ç‡è¿”å›å¯¹åº”çš„ CSS ç±»å"""
    if ai_prob > 0.75:
        return "ai-high"
    elif ai_prob > 0.5:
        return "ai-medium"
    else:
        return "ai-low"


def get_badge_class(ai_prob: float) -> str:
    """è·å–å¾½ç«  CSS ç±»å"""
    if ai_prob > 0.75:
        return "badge-high"
    elif ai_prob > 0.5:
        return "badge-medium"
    else:
        return "badge-low"


def format_ai_rate(ai_prob: float, human_prob: float) -> str:
    """æ ¼å¼åŒ– AI ç‡æ˜¾ç¤º"""
    ai_percent = f"{ai_prob*100:.1f}%"
    human_percent = f"{human_prob*100:.1f}%"
    
    # ç¡®å®šæ ‡ç­¾
    if ai_prob > 0.75:
        label = "ğŸ”´ é«˜åº¦ç–‘ä¼¼ AI"
    elif ai_prob > 0.5:
        label = "ğŸŸ¡ å¯èƒ½ AI"
    else:
        label = "ğŸŸ¢ å¯èƒ½äººç±»"
    
    return f"{label} | AI: {ai_percent} | äººç±»: {human_percent}"


def display_paragraph_result(para_num: int, paragraph: str, result: Dict, show_details: bool = False):
    """æ˜¾ç¤ºå•ä¸ªæ®µè½çš„æ£€æµ‹ç»“æœ - ç´§å‡‘æ ·å¼"""
    ai_prob = result["ai_prob"]
    human_prob = result["human_prob"]
    
    # ç¡®å®šé«˜äº®æ ·å¼
    if ai_prob > 0.75:
        highlight_class = "highlight-high"
        badge_class = "inline-badge-high"
        icon = "ğŸ”´"
    elif ai_prob > 0.5:
        highlight_class = "highlight-medium"
        badge_class = "inline-badge-medium"
        icon = "ğŸŸ¡"
    else:
        highlight_class = "highlight-low"
        badge_class = "inline-badge-low"
        icon = "ğŸŸ¢"
    
    # åˆ›å»ºç´§å‡‘çš„å†…è”æ˜¾ç¤º
    html_content = f"""
    <span class="text-segment {highlight_class}" title="AIç‡: {ai_prob*100:.1f}% | ç½®ä¿¡åº¦: {max(ai_prob, human_prob):.4f}">{paragraph}</span><span class="inline-badge {badge_class}">{icon}{ai_prob*100:.0f}%</span> 
    """
    
    st.markdown(html_content, unsafe_allow_html=True)


def main():
    """ä¸»å‡½æ•°"""
    
    # é¡¶éƒ¨æ ‡é¢˜
    st.title("AIGC æ–‡æœ¬æ£€æµ‹å™¨")
    st.markdown("### é€æ®µè½æ£€æµ‹ AI ç”Ÿæˆæ–‡æœ¬")
    
    # è¯­è¨€é€‰æ‹©å™¨
    language = st.radio(
        "é€‰æ‹©æ£€æµ‹è¯­è¨€ / Select Language",
        ("ğŸ‡¨ğŸ‡³ ä¸­æ–‡ (Chinese)", "ğŸ‡ºğŸ‡¸ è‹±æ–‡ (English)"),
        horizontal=True,
        help="ä¸­æ–‡æ¨¡å‹ï¼šyuchuantian/AIGC_detector_zhv3 | è‹±æ–‡æ¨¡å‹ï¼šyuchuantian/AIGC_detector_env3"
    )
    lang_code = "chinese" if "ä¸­æ–‡" in language else "english"
    
    # åŠ è½½æ£€æµ‹å™¨
    detector = load_detector(language=lang_code)
    
    # è¾“å…¥åŒºåŸŸ
    st.subheader("ğŸ“ è¾“å…¥æ–‡æœ¬")
    
    input_mode = st.radio(
        "é€‰æ‹©è¾“å…¥æ–¹å¼",
        ("ğŸ“„ ç›´æ¥è¾“å…¥æ–‡æœ¬", "ğŸ“ ä¸Šä¼ æ–‡ä»¶"),
        horizontal=True
    )
    
    text = ""
    
    if input_mode == "ğŸ“„ ç›´æ¥è¾“å…¥æ–‡æœ¬":
        placeholder_text = "åœ¨è¿™é‡Œç²˜è´´æˆ–è¾“å…¥æ‚¨è¦æ£€æµ‹çš„æ–‡æœ¬..." if lang_code == "chinese" else "Paste or type the text you want to detect here..."
        text = st.text_area(
            "è¯·è¾“å…¥è¦æ£€æµ‹çš„æ–‡æœ¬ (æ¯ä¸ªæ®µè½ä¼šå•ç‹¬æ£€æµ‹):",
            height=200,
            placeholder=placeholder_text,
            label_visibility="collapsed"
        )
    else:
        uploaded_file = st.file_uploader(
            "ä¸Šä¼ æ–‡ä»¶ (æ”¯æŒ txt, csv, pdf, docx, tex, md)",
            type=["txt", "csv", "pdf", "docx", "doc", "tex", "md"]
        )
        if uploaded_file:
            file_type = uploaded_file.name.split(".")[-1].lower()
            
            with st.spinner(f"æ­£åœ¨è§£æ {file_type.upper()} æ–‡ä»¶..."):
                if file_type == "pdf":
                    text = extract_text_from_pdf(uploaded_file)
                    if text:
                        st.success(f"âœ“ PDF è§£æå®Œæˆï¼Œæå– {len(text)} ä¸ªå­—ç¬¦")
                elif file_type in ["docx", "doc"]:
                    text = extract_text_from_docx(uploaded_file)
                    if text:
                        st.success(f"âœ“ Word æ–‡æ¡£è§£æå®Œæˆï¼Œæå– {len(text)} ä¸ªå­—ç¬¦")
                elif file_type == "tex":
                    text = extract_chinese_from_tex(uploaded_file)
                    if text:
                        st.success(f"âœ“ TeX ä¸­æ–‡å†…å®¹æå–å®Œæˆï¼Œæå– {len(text)} ä¸ªå­—ç¬¦")
                elif file_type == "md":
                    text = extract_text_from_md(uploaded_file)
                    if text:
                        st.success(f"âœ“ Markdown è§£æå®Œæˆï¼Œæå– {len(text)} ä¸ªå­—ç¬¦")
                elif file_type == "csv":
                    text = uploaded_file.read().decode("utf-8")
                else:  # txt
                    text = uploaded_file.read().decode("utf-8")
    
    # æ£€æµ‹æŒ‰é’®
    col1, col2, col3 = st.columns(3)
    
    if col1.button("ğŸ” å¼€å§‹æ£€æµ‹", use_container_width=False, type="primary"):
        
        if not text.strip():
            st.error("âŒ è¯·è¾“å…¥æ–‡æœ¬å†…å®¹")
        else:
            # åˆ†å‰²æ®µè½
            paragraphs = split_into_paragraphs(text)
            
            if not paragraphs:
                st.error("âŒ æ— æ³•è§£ææ–‡æœ¬")
            else:
                st.success(f"âœ“ å‘ç° {len(paragraphs)} ä¸ªæ®µè½ï¼Œæ­£åœ¨æ£€æµ‹...")
    
                # æ£€æµ‹æ‰€æœ‰æ®µè½
                progress_bar = st.progress(0)
                results = []
                
                for i, para in enumerate(paragraphs):
                    result = detector.detect_single(para)
                    results.append({
                        "æ®µè½": i + 1,
                        "æ–‡æœ¬": para,
                        "AIç‡": result["ai_prob"],
                        "äººç±»ç‡": result["human_prob"],
                        "ç½®ä¿¡åº¦": result["confidence"],
                        "é¢„æµ‹": result["prediction"]
                    })
                    progress_bar.progress((i + 1) / len(paragraphs))
            
            # æ˜¾ç¤ºå›¾è¡¨
            if len(results) > 0:
                st.markdown("---")
                st.subheader("ç»Ÿè®¡")
                
                # è®¡ç®—ç»Ÿè®¡æ•°æ®
                total_paragraphs = len(results)
                high_ai_count = sum(1 for r in results if r["AIç‡"] > 0.75)
                medium_and_high_count = sum(1 for r in results if r["AIç‡"] > 0.5)
                avg_ai_rate = sum(r["AIç‡"] for r in results) / total_paragraphs
                avg_confidence = sum(r["ç½®ä¿¡åº¦"] for r in results) / total_paragraphs
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                col1, col2, col3, col4, col5 = st.columns(5)
                with col1:
                    st.metric("æ€»æ®µè½æ•°", f"{total_paragraphs}")
                with col2:
                    st.metric("ç–‘ä¼¼åŠä»¥ä¸Š", f"{medium_and_high_count}")
                with col3:
                    st.metric("é«˜åº¦ç–‘ä¼¼", f"{high_ai_count}")
                with col4:
                    st.metric("å¹³å‡ AI ç‡", f"{avg_ai_rate*100:.1f}%")
                with col5:
                    st.metric("å¹³å‡ç½®ä¿¡åº¦", f"{avg_confidence:.3f}")
                
                st.markdown("<br>", unsafe_allow_html=True)
                
                # åˆ›å»ºä¸€ç»´æ¡å½¢å›¾ - æ‰€æœ‰æ®µè½åœ¨ä¸€è¡Œï¼Œå®½åº¦è¡¨ç¤ºå­—æ•°å æ¯”
                fig = go.Figure()
                
                total_chars = sum(len(r["æ–‡æœ¬"]) for r in results)
                
                # ä¸ºæ¯ä¸ªæ®µè½åˆ›å»ºä¸€ä¸ªå †å æ¡
                for i, r in enumerate(results):
                    # é¢œè‰²æ ¹æ® AI ç‡ï¼ˆæ¸å˜ï¼šç»¿ -> æ©™ -> çº¢ï¼‰
                    ai_rate = float(r["AIç‡"])

                    def _lerp(a: int, b: int, t: float) -> int:
                        return int(round(a + (b - a) * t))

                    def _hex_to_rgb(hex_color: str):
                        hex_color = hex_color.lstrip("#")
                        return int(hex_color[0:2], 16), int(hex_color[2:4], 16), int(hex_color[4:6], 16)

                    def _rgb_to_hex(rgb):
                        return f"#{rgb[0]:02x}{rgb[1]:02x}{rgb[2]:02x}"

                    def _ai_rate_to_color(p: float) -> str:
                        p = max(0.0, min(1.0, p))
                        c0 = "#4caf50"  # ä½ï¼šç»¿
                        c1 = "#ff921e"  # ä¸­ï¼šæ©™
                        c2 = "#f23535"  # é«˜ï¼šçº¢
                        # åˆ†æ®µè§„åˆ™ï¼ˆæŒ‰ç™¾åˆ†æ¯”ï¼‰ï¼š
                        # 0~20 çº¯ç»¿ï¼›20~50 å˜æ©™ï¼›50~60 çº¯æ©™ï¼›60~90 å˜çº¢ï¼›90~100 çº¯çº¢
                        # 10~20 æœªæŒ‡å®šï¼Œé»˜è®¤ä¿æŒçº¯ç»¿ï¼ˆä¸ 0~10 ä¸€è‡´ï¼‰
                        if p <= 0.20:
                            return c0
                        if p <= 0.50:
                            t = (p - 0.20) / 0.30
                            r0, g0, b0 = _hex_to_rgb(c0)
                            r1, g1, b1 = _hex_to_rgb(c1)
                            return _rgb_to_hex((_lerp(r0, r1, t), _lerp(g0, g1, t), _lerp(b0, b1, t)))
                        if p <= 0.60:
                            return c1
                        if p <= 0.90:
                            t = (p - 0.60) / 0.30
                            r1, g1, b1 = _hex_to_rgb(c1)
                            r2, g2, b2 = _hex_to_rgb(c2)
                            return _rgb_to_hex((_lerp(r1, r2, t), _lerp(g1, g2, t), _lerp(b1, b2, t)))
                        return c2

                    color = _ai_rate_to_color(ai_rate)
                    
                    # å®½åº¦æ ¹æ®å­—æ•°å æ¯”
                    width = len(r["æ–‡æœ¬"]) / total_chars * 100
                    
                    fig.add_trace(go.Bar(
                        name=f"æ®µè½ {r['æ®µè½']}",
                        x=[width],
                        y=["å…¨æ–‡"],
                        orientation='h',
                        marker=dict(
                            color=color,
                            line=dict(width=0)
                        ),
                        hovertemplate=f"<b>æ®µè½ {r['æ®µè½']}</b><br>å­—æ•°: {len(r['æ–‡æœ¬'])}<br>AIç‡: {r['AIç‡']*100:.1f}%<extra></extra>"
                    ))
                
                fig.update_layout(
                    title="æ¦‚è§ˆ",
                    xaxis=dict(
                        title="",
                        showticklabels=False,
                        showgrid=False
                    ),
                    yaxis=dict(
                        showticklabels=False,
                        showgrid=False
                    ),
                    barmode='stack',
                    height=150,
                    showlegend=False,
                    margin=dict(l=0, r=0, t=40, b=20)
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
            
                # æ®µè½è§†å›¾
                st.markdown("---")
                st.subheader("ğŸ“„ æ®µè½è§†å›¾")
                
                # æ˜¾ç¤ºæ‰€æœ‰æ®µè½
                for result in results:
                    display_paragraph_result(result["æ®µè½"], result["æ–‡æœ¬"], {
                        "ai_prob": result["AIç‡"],
                        "human_prob": result["äººç±»ç‡"],
                        "confidence": result["ç½®ä¿¡åº¦"]
                    })
                
                # æ˜¾ç¤ºå¯¼å‡ºæŒ‰é’®
                st.markdown("---")
                
                # å¯¼å‡ºä¸º CSV
                csv_data = pd.DataFrame(results)
                csv_data["AIç‡"] = csv_data["AIç‡"].apply(lambda x: f"{x*100:.1f}%")
                csv_data["äººç±»ç‡"] = csv_data["äººç±»ç‡"].apply(lambda x: f"{x*100:.1f}%")
                
                csv = csv_data.to_csv(index=False)
                
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½æ£€æµ‹ç»“æœ (CSV)",
                    data=csv,
                    file_name="detection_results.csv",
                    mime="text/csv",
                    use_container_width=True
                )
    
    
    # é¡µè„šä¿¡æ¯
    st.markdown("---")
    model_display = "yuchuantian/AIGC_detector_zhv3" if lang_code == "chinese" else "yuchuantian/AIGC_detector_env3"
    st.markdown(f"""
    <div style='text-align: center; color: #888; font-size: 12px;'>
        <p>
        AIGC æ£€æµ‹å™¨ v3.0 | 
        å½“å‰æ¨¡å‹: {model_display} | 
        å‡†ç¡®ç‡: 97%+
        </p>
        <p>
        ğŸ“Œ æç¤º: ç½®ä¿¡åº¦è¶Šé«˜ï¼Œé¢„æµ‹è¶Šå¯é  | 
        âš ï¸ ä»…ä¾›å­¦æœ¯ç ”ç©¶ä½¿ç”¨
        </p>
    </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()
